{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76998d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SIMIYOUNG\\Documents\\Python-Projects\\streamlit\\Automated-Streamlit-Deployment-Churn-Prediction--main\n"
     ]
    }
   ],
   "source": [
    "#Configure os folder\n",
    "import os\n",
    "# Create a folder for the pipeline step files\n",
    "experiment_folder = r'C:\\Users\\SIMIYOUNG\\Documents\\Python-Projects\\streamlit\\Automated-Streamlit-Deployment-Churn-Prediction--main'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19a8ea5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C:\\Users\\SIMIYOUNG\\Documents\\Python-Projects\\streamlit\\Automated-Streamlit-Deployment-Churn-Prediction--main/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/app.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "st.set_option('deprecation.showPyplotGlobalUse', False)\n",
    "\n",
    "st.title(\"Churn Prediction\")\n",
    "\n",
    "st.header('Dataset Selection and Loading')\n",
    "dataset_name = st.selectbox(\"Select Datasets\", ['Telco_Churn'])\n",
    "st.write('You selected:', dataset_name, 'dataset')\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "    df = pd.read_csv(\"telecom.csv\")\n",
    "    target_column = \"Churn\"\n",
    "    df[\"SeniorCitizen\"] = df[\"SeniorCitizen\"].replace([0, 1], ['No', 'Yes'])\n",
    "    df[\"TotalCharges\"] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "\n",
    "    return df, target_column\n",
    "\n",
    "\n",
    "df, target_column = get_dataset()\n",
    "df1 = df.copy()\n",
    "\n",
    "st.subheader('Checking the Dataset')\n",
    "st.table(df.head())\n",
    "st.subheader('Types of Variables')\n",
    "pd.DataFrame(df.dtypes, columns = [\"Col\"])\n",
    "\n",
    "st.subheader('Exploratory Data Analysis')\n",
    "visualization = st.selectbox('Select Visualization Type', ('Pairplot', 'Heatmap'))\n",
    "if visualization == 'Pairplot':\n",
    "    fig = sns.pairplot(df, hue=target_column)\n",
    "    st.pyplot(fig=fig)\n",
    "elif visualization == 'Heatmap':\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(df.corr(), vmin=-1, cmap='coolwarm', annot=True)\n",
    "    st.pyplot(fig)\n",
    "\n",
    "st.header('Columns Selection for Analysis')\n",
    "st.cache()\n",
    "columns_select = st.selectbox(\"Select All Columns or Select Columns You Want to Drop\",\n",
    "                              (\"All Columns\", \"Select Columns to Drop\"))\n",
    "if columns_select == \"Select Columns to Drop\":\n",
    "    d_list = st.multiselect(\"Please select columns to be dropped\", df.columns)\n",
    "    df = df.drop(d_list, axis=1)\n",
    "    if st.button(\"Generate Codes for Columns to be Dropped\"):\n",
    "        if columns_select == \"Select Columns to Drop\":\n",
    "            st.code(f\"\"\"df = df.drop({d_list},axis=1)\"\"\")\n",
    "\n",
    "st.header('Multicollinearity Checking')\n",
    "threshold = st.selectbox(\"Select threshold for multicollinearity\", (1, 0.9, 0.8, 0.7))\n",
    "Corr_Columns = []\n",
    "numeric_cols = df.select_dtypes(exclude=[\"object\"]).columns\n",
    "\n",
    "\n",
    "def multicollinearity(dataset, threshold):\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                colname = corr_matrix.columns[i]\n",
    "                Corr_Columns.append(colname)\n",
    "    return Corr_Columns\n",
    "\n",
    "\n",
    "multicollinearity(df, threshold=threshold)\n",
    "\n",
    "df.drop(Corr_Columns, axis=1, inplace=True)\n",
    "if len(Corr_Columns) > 0:\n",
    "    st.write(f\"{Corr_Columns} columns having correlation value more than {threshold} and therefore dropped\")\n",
    "else:\n",
    "    st.write(\"No columns found exceeding the threshold\")\n",
    "\n",
    "st.header('Checking Missing Values')\n",
    "threshold_value = st.selectbox(\"Select Threshold for Missing Value Checking\", (70, 60, 50, 40, 30, 20, 10))\n",
    "drop_list = []\n",
    "\n",
    "\n",
    "def missing_drop(df, threshold_value):\n",
    "    for variable in df.columns:\n",
    "        percentage = round((df[variable].isnull().sum() / df[variable].count()) * 10)\n",
    "        if percentage > threshold_value:\n",
    "            st.write(f\"The percentage of missing variable for {variable} is % {percentage}\")\n",
    "            drop_list.append(variable)\n",
    "    if len(drop_list) == 0:\n",
    "        st.write(\"No Columns exceeding the Threshold\")\n",
    "\n",
    "\n",
    "missing_drop(df, threshold_value)\n",
    "\n",
    "st.header('Missing Value Handling')\n",
    "missing_values = st.selectbox(\"Select one method for missing value imputation \",\n",
    "                              (\"Drop All Missing Values\", \"Filling with Either Median or Mode\"))\n",
    "\n",
    "\n",
    "def impute_with_median(df, variable):\n",
    "    if df[variable].isnull().sum() > 0:\n",
    "        st.write(\n",
    "            f\"{variable} column has {df[variable].isnull().sum()} missing value and replaced with median:{df[variable].median()}\")\n",
    "        df[variable + \"NAN\"] = np.where(df[variable].isnull(), 1, 0)\n",
    "        df[variable] = df[variable].fillna(df[variable].median())\n",
    "\n",
    "\n",
    "def impute_with_mode(df, variable):\n",
    "    if df[variable].isnull().sum() > 0:\n",
    "        st.write(\n",
    "            f\"{variable} column has {df[variable].isnull().sum()} missing value and replaced {df[variable].mode()[0]}\")\n",
    "        df[variable + \"NAN\"] = np.where(df[variable].isnull(), 1, 0)\n",
    "        frequent = df[variable].mode()[0]\n",
    "        df[variable].fillna(frequent, inplace=True)\n",
    "\n",
    "\n",
    "if missing_values == \"Drop All Missing Values\":\n",
    "    for variable in df.columns:\n",
    "        if df[variable].isnull().sum() > 0:\n",
    "            st.write(f\"{variable} column has {df[variable].isnull().sum()} missing value\")\n",
    "    st.write(f\" percentages of total missing data :% {(df.isnull().sum().sum() / df.shape[0]) * 10}\")\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "else:\n",
    "    for i in df.columns:\n",
    "        if np.dtype(df[i]) == \"object\":\n",
    "            impute_with_mode(df, i)\n",
    "        else:\n",
    "            impute_with_median(df, i)\n",
    "\n",
    "st.header('Outliers Detection and Handling')\n",
    "\n",
    "Handling_Outliers = st.selectbox(\"Select One Option for Outlier Handling \", (\"Keep Outliers\", \"Handle Outliers\"))\n",
    "numeric_cols = df.select_dtypes(exclude=[\"object\"]).columns\n",
    "\n",
    "\n",
    "def outliers_detection_handling(df, variable):\n",
    "    IQR = df[variable].quantile(0.75) - df[variable].quantile(0.25)\n",
    "    lower_bound = df[variable].quantile(0.25) - (IQR * 1.5)\n",
    "    upper_bound = df[variable].quantile(0.75) + (IQR * 1.5)\n",
    "    df[variable] = np.where(df[variable] > upper_bound, upper_bound, df[variable])\n",
    "    df[variable] = np.where(df[variable] < lower_bound, lower_bound, df[variable])\n",
    "    return df[variable]\n",
    "\n",
    "\n",
    "if Handling_Outliers == \"Handle Outliers\":\n",
    "    for i in numeric_cols:\n",
    "        IQR = df[i].quantile(0.75) - df[i].quantile(0.25)\n",
    "        lower_bound = df[i].quantile(0.25) - (IQR * 1.5)\n",
    "        upper_bound = df[i].quantile(0.75) + (IQR * 1.5)\n",
    "        num_outliers = df[~df[i].between(lower_bound, upper_bound)].value_counts().sum()\n",
    "        if (df[i].max() > upper_bound) | (df[i].min() < lower_bound):\n",
    "            outliers_detection_handling(df, i)\n",
    "            st.write(f\"{i}  column has {num_outliers} outliers and set to either upper or lower bound.\")\n",
    "else:\n",
    "    st.write(\"You are keeping all outliers\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "st.header('One Hot Encoding')\n",
    "y = df[target_column]\n",
    "X = df.drop(target_column, axis=1)\n",
    "df = X\n",
    "encode_list = []\n",
    "\n",
    "\n",
    "def one_hot_encoder(df):\n",
    "    for i in X.columns:\n",
    "        if (np.dtype(df[i]) == \"object\"):\n",
    "            unique_value = len(df[i].value_counts().sort_values(ascending=False).head(10).index)\n",
    "            if unique_value > 10:\n",
    "                for categories in (df[i].value_counts().sort_values(ascending=False).head(10).index):\n",
    "                    df[i + \"_\" + categories] = np.where(df[i] == categories, 1, 0)\n",
    "                    encode_list.append(i + \"_\" + categories)\n",
    "\n",
    "            else:\n",
    "                for categories in (df[i].value_counts().sort_values(ascending=False).head(unique_value - 1).index):\n",
    "                    df[i + \"_\" + categories] = np.where(df[i] == categories, 1, 0)\n",
    "                    encode_list.append(i + \"_\" + categories)\n",
    "\n",
    "    return df, encode_list\n",
    "\n",
    "\n",
    "num_cat_col = len(df.select_dtypes(include=[\"object\"]).columns)\n",
    "one_hot_encoder(df)\n",
    "\n",
    "for i in df.columns:\n",
    "    if (np.dtype(df[i]) == \"object\"):\n",
    "        df = df.drop([i], axis=1)\n",
    "col_after_endoded_all = df.columns\n",
    "st.write(f\"One hot encoding : {num_cat_col} columns are encoded and  {len(encode_list)} new columns are added\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "st.header('Feature Engineering')\n",
    "feature_selection = st.selectbox(\"Feature Selection\", (\"Keep all Features\", \"Select Features\"))\n",
    "\n",
    "\n",
    "def feature_importance(endogenous, exogenous, n):\n",
    "    selected_feat = SelectKBest(score_func=chi2, k=10)\n",
    "    selected = selected_feat.fit(endogenous, exogenous)\n",
    "    feature_score = pd.DataFrame(selected.scores_, index=endogenous.columns, columns=[\"Score\"])[\"Score\"].sort_values(\n",
    "        ascending=False).reset_index()\n",
    "    st.write(\"Table: Feature Importance\")\n",
    "    st.table(feature_score.head(n))\n",
    "    st.write(\"Feature Importance\")\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    sns.barplot(data=feature_score.sort_values(by='Score', ascending=False).head(n), x='Score', y='index')\n",
    "    st.pyplot()\n",
    "    X_Selected.extend(feature_score[\"index\"].head(n))\n",
    "\n",
    "\n",
    "if feature_selection == \"Select Features\":\n",
    "    st.write()\n",
    "    feature_number = st.slider(\"Select Number of Features You Want to Observe by Using Slider\", 1, df.shape[1])\n",
    "    X_Selected = []\n",
    "    feature_importance(df, y, feature_number)\n",
    "    df = df[X_Selected]\n",
    "else:\n",
    "    st.write(f\"You selected all features and the number of selected features is: {len(df.columns)}\")\n",
    "\n",
    "st.header('Standardization')\n",
    "standardization = st.selectbox(\"Standardization\", (\"No Need to Apply Standardization\", \"Apply Standardization\"))\n",
    "if standardization == 'Apply Standardization':\n",
    "    methods = st.selectbox(\"Select one of the Standardization Methods: \",\n",
    "                           (\"StandardScaler\", \"MinMaxScaler\", \"RobustScaler\"))\n",
    "\n",
    "    num_cols = []\n",
    "    df_new = df1.drop(target_column, axis=1)\n",
    "    numeric_cols = df_new.select_dtypes(exclude=[\"object\"]).columns\n",
    "    for i in numeric_cols:\n",
    "        if i not in df.columns:\n",
    "            pass\n",
    "        else:\n",
    "            num_cols.append(i)\n",
    "\n",
    "    for i in num_cols:\n",
    "        if methods == \"StandardScaler\":\n",
    "            scaler = StandardScaler()\n",
    "            df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "        elif methods == \"MinMaxScaler\":\n",
    "            scaler = MinMaxScaler()\n",
    "            df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "        else:\n",
    "            scaler = RobustScaler()\n",
    "            df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "    st.write(f\"{num_cols} are scaled by using {methods}\")\n",
    "\n",
    "st.header('Model Evaluation')\n",
    "models_name = st.sidebar.selectbox(\"Select Model for ML\", (\"LightGBM\", \"Random Forest\"))\n",
    "params = dict()\n",
    "\n",
    "\n",
    "def parameter_selection(clf_name):\n",
    "    if clf_name == \"LightGBM\":\n",
    "        st.sidebar.write(\"Select Parameters\")\n",
    "        n_estimators = st.sidebar.slider(\"n_estimators\", 10, 1000, 100, 10)\n",
    "        max_depth = st.sidebar.slider(\"max_depth\", 3, 20,1,1)\n",
    "        learning_rate = st.sidebar.slider('learning_rate', 0.01, 1.0, 0.1, 0.1)\n",
    "        num_leaves = st.sidebar.slider('num_leaves', 10, 300, 31, 10)\n",
    "        params[\"n_estimators\"] = n_estimators\n",
    "        params[\"max_depth\"] = max_depth\n",
    "        params[\"num_leaves\"] = num_leaves\n",
    "        params[\"learning_rate\"] = learning_rate\n",
    "\n",
    "    else:\n",
    "        st.sidebar.write(\"Select Parameters\")\n",
    "        max_depth = st.sidebar.slider(\"max_depth\", 2, 100, 1, 2)\n",
    "        n_estimators = st.sidebar.slider(\"n_estimators\", 50, 1000, 100, 10)\n",
    "        criterion = st.sidebar.selectbox(\"criterion\", ('gini','entropy'))\n",
    "        max_features = st.sidebar.selectbox(\"max_features\", ('auto', 'sqrt', 'log2'))\n",
    "        min_samples_leaf = st.sidebar.slider(\"min_samples_leaf\", 1, 10, 5)\n",
    "        min_samples_split = st.sidebar.slider(\"min_samples_split\", 2, 10)\n",
    "        params[\"max_depth\"] = max_depth\n",
    "        params[\"n_estimators\"] = n_estimators\n",
    "        params[\"criterion\"] = criterion\n",
    "        params[\"max_features\"] = max_features\n",
    "        params[\"min_samples_leaf\"] = min_samples_leaf\n",
    "        params[\"min_samples_split\"] = min_samples_split\n",
    "        a = RandomForestClassifier()\n",
    "    return params\n",
    "\n",
    "\n",
    "parameter_selection(models_name)\n",
    "\n",
    "\n",
    "def get_classifier(classifier_name, params):\n",
    "\n",
    "    if classifier_name == \"LightGBM\":\n",
    "\n",
    "        clf_model = LGBMClassifier(num_leaves=params[\"num_leaves\"], n_estimators=params[\"n_estimators\"], max_depth=params[\"max_depth\"], learning_rate=params[\"learning_rate\"], random_state=42)\n",
    "    else:\n",
    "        clf_model = RandomForestClassifier(n_estimators=params[\"n_estimators\"], max_depth=params[\"max_depth\"],\n",
    "                                            criterion=params[\"criterion\"], max_features=params[\"max_features\"],\n",
    "                                            min_samples_leaf=params[\"min_samples_leaf\"],\n",
    "                                            min_samples_split=params[\"min_samples_split\"], random_state=42)\n",
    "\n",
    "    return clf_model\n",
    "\n",
    "\n",
    "clf_model = get_classifier(models_name, params)\n",
    "st.cache()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)\n",
    "clf_model.fit(X_train, y_train)\n",
    "y_pred = clf_model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1_scr = f1_score(y_test, y_pred, average='macro')\n",
    "cls_report = classification_report(y_test, y_pred)\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "st.sidebar.write(f\"Selected Classifier = {models_name}\")\n",
    "st.sidebar.write(f\"Accuracy Score = {acc}\")\n",
    "st.write(f\"Selected Classifier = {models_name}\")\n",
    "st.write(f\"Accuracy Score = {acc}\")\n",
    "st.subheader('Confusion Matrix')\n",
    "st.table(cnf_matrix)\n",
    "st.subheader('Classification Report')\n",
    "st.text('Classification Report:\\n ' + cls_report)\n",
    "\n",
    "st.header('Model Download')\n",
    "st.cache()\n",
    "\n",
    "\n",
    "def download_model(model):\n",
    "    pickle.dump(clf_model, open(\"final_model\", 'wb'))\n",
    "\n",
    "\n",
    "download_model(clf_model)\n",
    "st.write(f'Trained model is saved as final_model for later use')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "st.header('Churn Probability of Customers')\n",
    "if st.button(\"Prediction Probality of Top 10 Churned Customers\"):\n",
    "    col_val = ['0', '1']\n",
    "    a = clf_model.predict_proba(X_test)\n",
    "    b = pd.DataFrame(data=a, columns=col_val)\n",
    "    sorted_val = b.sort_values(by='0', ascending=False)\n",
    "    st.table(sorted_val.head(10))\n",
    "\n",
    "\n",
    "if st.button(\"Prediction Probality of Top 20 Loyal Customers\"):\n",
    "    col_val = ['0', '1']\n",
    "    a = clf_model.predict_proba(X_test)\n",
    "    b = pd.DataFrame(data=a, columns=col_val)\n",
    "    sorted_val = b.sort_values(by='0')\n",
    "    st.table(sorted_val.head(20))\n",
    "\n",
    "st.header('Prediction')\n",
    "st.subheader(\"Please select your variables to predict\")\n",
    "st.write('Please **do not leave** Tenure, Montly Charges, and Total Charges columns **empty**')\n",
    "df1.drop(target_column, axis=1, inplace=True)\n",
    "df1.drop('customerID', axis=1, inplace=True)\n",
    "columns = df1.columns\n",
    "cat_columns = df1.select_dtypes(include=[\"object\"]).columns\n",
    "dftest = pd.DataFrame()\n",
    "\n",
    "\n",
    "for i in df1.columns:\n",
    "    if i not in cat_columns:\n",
    "        try:\n",
    "            dftest[i] = [int(st.text_input(i))]\n",
    "        except:\n",
    "            dftest[i] = np.nan\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            dftest[i] = [st.selectbox(i, df1[i].value_counts().index.tolist())]\n",
    "        except:\n",
    "            dftest[i] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "def prediction(dftest):\n",
    "    try:\n",
    "        dftest.drop(corCol, axis=1, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        dftest.drop(d_list, axis=1, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    def impute_with_median(df, variable):\n",
    "        if df[variable].isnull().sum() > 0:\n",
    "            df[variable + \"NAN\"] = np.where(df[variable].isnull(), 1, 0)\n",
    "            df[variable] = df[variable].fillna(dftest[variable].median())\n",
    "\n",
    "    def impute_with_mode(df, variable):\n",
    "        if df[variable].isnull().sum() > 0:\n",
    "            df[variable + \"NAN\"] = np.where(df[variable].isnull(), 1, 0)\n",
    "            frequent = dftest[variable].mode()[0]\n",
    "            df[variable].fillna(frequent, inplace=True)\n",
    "\n",
    "    for i in dftest.columns:\n",
    "        if (np.dtype(dftest[i]) == \"object\"):\n",
    "            impute_with_mode(dftest, i)\n",
    "        else:\n",
    "            impute_with_median(dftest, i)\n",
    "\n",
    "    def outliers_detection_handling(df, variable):\n",
    "        IQR = df[variable].quantile(0.75) - df[variable].quantile(0.25)\n",
    "        lower_bound = df[variable].quantile(0.25) - (IQR * 1.5)\n",
    "        upper_bound = df[variable].quantile(0.75) + (IQR * 1.5)\n",
    "        df[variable] = np.where(df[variable] > upper_bound, upper_bound, df[variable])\n",
    "        df[variable] = np.where(df[variable] < lower_bound, lower_bound, df[variable])\n",
    "        return df[variable]\n",
    "\n",
    "    try:\n",
    "        if Handling_Outliers == \"Handle Outliers\":\n",
    "            for i in numeric_cols:\n",
    "                outliers_detection_handling(dftest, i)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    def one_hot_encoder(df):\n",
    "        for i in encode_list:\n",
    "            try:\n",
    "                for categories in df[i]:\n",
    "                    df[i] = np.where(df[i] == categories, 1, 0)\n",
    "            except:\n",
    "                df[i] = np.where(False, 1, 0)\n",
    "\n",
    "        return df\n",
    "\n",
    "    one_hot_encoder(dftest)\n",
    "\n",
    "    for i in col_after_endoded_all:\n",
    "        if i not in dftest.columns:\n",
    "            dftest[i] = np.where(False, 1, 0)\n",
    "\n",
    "    dftest = dftest.loc[:, col_after_endoded_all]\n",
    "    dftest = dftest.drop(dftest.select_dtypes(\"object\").columns, axis=1)\n",
    "\n",
    "    if feature_selection == \"Select Features\":\n",
    "        dftest = dftest[X_Selected]\n",
    "\n",
    "    if standardization == 'Apply Standardization':\n",
    "        try:\n",
    "            dftest[num_cols] = scaler.fit_transform(dftest[num_cols])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    result = clf_model.predict(dftest)\n",
    "    st.text('Predicted Result based on Data given is :' + ' ' + result)\n",
    "\n",
    "\n",
    "if st.button(\"Predict\"):\n",
    "    prediction(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b14f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_dataset():\n",
    "    df = pd.read_csv(\"telecom.csv\", index_col = [0])\n",
    "    target_column = \"Churn\"\n",
    "    df[\"SeniorCitizen\"] = df[\"SeniorCitizen\"].replace([0, 1], ['No', 'Yes'])\n",
    "    df[\"TotalCharges\"] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "\n",
    "    return df, target_column\n",
    "\n",
    "df, target = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfcb1240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tenure</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalCharges</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customerID_1015-OWJKI</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customerID_8263-OKETD</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customerID_7632-YUTXB</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customerID_1140-UKVZG</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customerID_1241-EZFMJ</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customerID_0925-VYDLG</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customerID_7422-WNBTY</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customerID_9251-WNSOD</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customerID_6196-HBOBZ</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender_Male</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SeniorCitizen_No</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Partner_No</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependents_No</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhoneService_Yes</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultipleLines_No</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultipleLines_Yes</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InternetService_Fiber optic</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InternetService_DSL</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnlineSecurity_No</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnlineSecurity_Yes</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnlineBackup_No</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnlineBackup_Yes</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeviceProtection_No</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeviceProtection_Yes</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TechSupport_No</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TechSupport_Yes</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StreamingTV_No</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StreamingTV_Yes</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StreamingMovies_No</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StreamingMovies_Yes</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contract_Month-to-month</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contract_Two year</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaperlessBilling_Yes</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaymentMethod_Bank transfer (automatic)</th>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Col\n",
       "tenure                                     int64\n",
       "MonthlyCharges                           float64\n",
       "TotalCharges                             float64\n",
       "customerID_1015-OWJKI                      int32\n",
       "customerID_8263-OKETD                      int32\n",
       "customerID_7632-YUTXB                      int32\n",
       "customerID_1140-UKVZG                      int32\n",
       "customerID_1241-EZFMJ                      int32\n",
       "customerID_0925-VYDLG                      int32\n",
       "customerID_7422-WNBTY                      int32\n",
       "customerID_9251-WNSOD                      int32\n",
       "customerID_6196-HBOBZ                      int32\n",
       "gender_Male                                int32\n",
       "SeniorCitizen_No                           int32\n",
       "Partner_No                                 int32\n",
       "Dependents_No                              int32\n",
       "PhoneService_Yes                           int32\n",
       "MultipleLines_No                           int32\n",
       "MultipleLines_Yes                          int32\n",
       "InternetService_Fiber optic                int32\n",
       "InternetService_DSL                        int32\n",
       "OnlineSecurity_No                          int32\n",
       "OnlineSecurity_Yes                         int32\n",
       "OnlineBackup_No                            int32\n",
       "OnlineBackup_Yes                           int32\n",
       "DeviceProtection_No                        int32\n",
       "DeviceProtection_Yes                       int32\n",
       "TechSupport_No                             int32\n",
       "TechSupport_Yes                            int32\n",
       "StreamingTV_No                             int32\n",
       "StreamingTV_Yes                            int32\n",
       "StreamingMovies_No                         int32\n",
       "StreamingMovies_Yes                        int32\n",
       "Contract_Month-to-month                    int32\n",
       "Contract_Two year                          int32\n",
       "PaperlessBilling_Yes                       int32\n",
       "PaymentMethod_Electronic check             int32\n",
       "PaymentMethod_Mailed check                 int32\n",
       "PaymentMethod_Bank transfer (automatic)    int32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.dtypes, columns = [\"Col\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
